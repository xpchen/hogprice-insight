"""é‡æ–°å¯¼å…¥é›†å›¢ä¼ä¸šæ—¥åº¦æ•°æ®ï¼ˆå«è¥¿å—æ±‡æ€»æˆäº¤ç‡ï¼‰
ç”¨æ³•: python scripts/import_enterprise_daily.py [Excelæ–‡ä»¶è·¯å¾„]
ä¸ä¼ è·¯å¾„æ—¶ï¼Œè‡ªåŠ¨åœ¨ docs/ç”ŸçŒª/é›†å›¢ä¼ä¸š/ ä¸‹æŸ¥æ‰¾ 3.1ã€é›†å›¢ä¼ä¸šå‡ºæ è·Ÿè¸ªã€åˆ†çœåŒºã€‘.xlsx
"""
# -*- coding: utf-8 -*-
import sys
import io
from pathlib import Path

if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

script_dir = Path(__file__).parent.parent
sys.path.insert(0, str(script_dir))


def excel_has_southwest_sheet(path: Path) -> bool:
    """æ£€æŸ¥ Excel æ˜¯å¦åŒ…å« è¥¿å—æ±‡æ€» æˆ– CR5æ—¥åº¦ sheet"""
    try:
        import pandas as pd
        xl = pd.ExcelFile(path, engine='openpyxl')
        return 'è¥¿å—æ±‡æ€»' in xl.sheet_names or 'CR5æ—¥åº¦' in xl.sheet_names
    except Exception:
        return False


from app.core.database import SessionLocal
from app.models.sys_user import SysUser
from app.services.ingestors.unified_ingestor import unified_import
from app.models.dim_metric import DimMetric
from app.models.fact_observation import FactObservation
from sqlalchemy import func


def find_enterprise_daily_file() -> Path | None:
    """æŸ¥æ‰¾é›†å›¢ä¼ä¸šå‡ºæ è·Ÿè¸ª Excel æ–‡ä»¶ï¼ˆå« CR5æ—¥åº¦ã€è¥¿å—æ±‡æ€» sheetï¼‰"""
    # ä¼˜å…ˆï¼šæ ‡å‡†æ–‡ä»¶å
    priority = [
        script_dir.parent / "docs" / "ç”ŸçŒª" / "é›†å›¢ä¼ä¸š" / "3.1ã€é›†å›¢ä¼ä¸šå‡ºæ è·Ÿè¸ªã€åˆ†çœåŒºã€‘.xlsx",
        script_dir.parent / "docs" / "é›†å›¢ä¼ä¸šå‡ºæ è·Ÿè¸ªã€åˆ†çœåŒºã€‘.xlsx",
    ]
    for p in priority:
        if p.exists():
            return p
    # å…¶æ¬¡ï¼šé€’å½’æŸ¥æ‰¾å« è¥¿å—æ±‡æ€» æˆ– CR5æ—¥åº¦ çš„ xlsx
    docs_dir = script_dir.parent / "docs"
    if docs_dir.exists():
        for p in sorted(docs_dir.rglob("*.xlsx")):
            if "~$" in p.name:
                continue
            if excel_has_southwest_sheet(p):
                return p
    return None


def main():
    file_path = None
    if len(sys.argv) >= 2:
        file_path = Path(sys.argv[1])
        if not file_path.exists():
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            sys.exit(1)
    else:
        file_path = find_enterprise_daily_file()
        if not file_path:
            print("âŒ æœªæ‰¾åˆ°é›†å›¢ä¼ä¸šå‡ºæ è·Ÿè¸ª Excel æ–‡ä»¶")
            print("   è¯·å°†æ–‡ä»¶æ”¾åˆ° docs/ç”ŸçŒª/é›†å›¢ä¼ä¸š/3.1ã€é›†å›¢ä¼ä¸šå‡ºæ è·Ÿè¸ªã€åˆ†çœåŒºã€‘.xlsx")
            print("   æˆ–æ‰§è¡Œ: python scripts/import_enterprise_daily.py <æ–‡ä»¶è·¯å¾„>")
            sys.exit(1)

    print(f"ğŸ“‚ å¯¼å…¥æ–‡ä»¶: {file_path}")
    with open(file_path, 'rb') as f:
        file_content = f.read()

    db = SessionLocal()
    try:
        user = db.query(SysUser).filter(SysUser.username == "admin").first()
        if not user:
            user = db.query(SysUser).first()
        uploader_id = user.id if user else 1

        print("â³ æ‰§è¡Œå¯¼å…¥...")
        result = unified_import(
            db=db,
            file_content=file_content,
            filename=file_path.name,
            uploader_id=uploader_id,
            dataset_type="ENTERPRISE_DAILY",
            source_code="ENTERPRISE"
        )

        success = result.get("success", False)
        inserted = result.get("inserted", 0)
        updated = result.get("updated", 0)
        errors = result.get("errors", [])
        if isinstance(errors, int):
            error_count = errors
            errors = []
        else:
            error_count = len(errors)

        print(f"\nğŸ“Š å¯¼å…¥ç»“æœ:")
        print(f"   æˆåŠŸ: {success}")
        print(f"   æ’å…¥: {inserted} æ¡")
        print(f"   æ›´æ–°: {updated} æ¡")
        print(f"   é”™è¯¯: {error_count} ä¸ª")
        if errors:
            for e in (errors[:5] if isinstance(errors, list) else []):
                print(f"      - {e.get('reason', e)}")

        # éªŒè¯å››å·ã€å¹¿è¥¿æˆäº¤ç‡æ•°æ®
        print("\nğŸ“‹ éªŒè¯æˆäº¤ç‡æ•°æ®ï¼ˆå››å· E åˆ—ã€å¹¿è¥¿ K åˆ—ï¼‰:")
        tx_metric = db.query(DimMetric).filter(
            DimMetric.sheet_name == "è¥¿å—æ±‡æ€»",
            func.json_extract(DimMetric.parse_json, '$.metric_key') == 'SOUTHWEST_TRANSACTION_RATE'
        ).first()

        if tx_metric:
            for region in ["å››å·", "å¹¿è¥¿"]:
                count = db.query(FactObservation).filter(
                    FactObservation.metric_id == tx_metric.id,
                    func.json_extract(FactObservation.tags_json, '$.region') == region
                ).count()
                if count > 0:
                    sample = db.query(FactObservation).filter(
                        FactObservation.metric_id == tx_metric.id,
                        func.json_extract(FactObservation.tags_json, '$.region') == region
                    ).order_by(FactObservation.obs_date.desc()).first()
                    print(f"   âœ“ {region} æˆäº¤ç‡: {count} æ¡ (æœ€æ–°: {sample.obs_date} = {sample.value}%)")
                else:
                    print(f"   âš  {region} æˆäº¤ç‡: 0 æ¡")
            print("\nâœ“ æˆäº¤ç‡æ•°æ®å·²æ­£ç¡®è§£æï¼ˆå®é™…æˆäº¤/æŒ‚ç‰Œï¼‰")
        else:
            # å…¼å®¹ï¼šæ£€æŸ¥æ—§å®Œæˆç‡
            old_metric = db.query(DimMetric).filter(
                DimMetric.sheet_name == "è¥¿å—æ±‡æ€»",
                func.json_extract(DimMetric.parse_json, '$.metric_key') == 'SOUTHWEST_COMPLETION_RATE'
            ).first()
            if old_metric:
                print("   âš  å½“å‰ä¸ºæ—§æŒ‡æ ‡ SOUTHWEST_COMPLETION_RATEï¼Œè¯·ç¡®è®¤ Excel ç¬¬2è¡Œæœ‰ã€Œæˆäº¤ç‡ã€åˆ—")
            else:
                print("   âš  æœªæ‰¾åˆ°æˆäº¤ç‡æŒ‡æ ‡ï¼Œè¯·æ£€æŸ¥è¥¿å—æ±‡æ€» sheet ç»“æ„")

        print("\nâœ… å¯¼å…¥å®Œæˆ")
    except Exception as e:
        db.rollback()
        print(f"\nâŒ å¯¼å…¥å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
    finally:
        db.close()


if __name__ == "__main__":
    main()
