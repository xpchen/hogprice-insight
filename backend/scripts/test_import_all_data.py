"""äº”ç±»æ•°æ®å…¨é‡å…¥åº“è‡ªæµ‹è„šæœ¬

è‡ªåŠ¨å¯¼å…¥ä»¥ä¸‹äº”ç±»æ•°æ®ï¼š
1. é’¢è”è‡ªåŠ¨æ›´æ–°æ¨¡æ¿.xlsx - GANGLIAN_DAILY
2. 2026å¹´2æœˆ2æ—¥æ¶Œç›Šå’¨è¯¢æ—¥åº¦æ•°æ®.xlsx - YONGYI_DAILY
3. lh_ftr.xlsx - LH_FTR
4. lh_opt.xlsx - LH_OPT
5. 2026.1.16-2026.1.22æ¶Œç›Šå’¨è¯¢ å‘¨åº¦æ•°æ®.xlsx - YONGYI_WEEKLY
"""
import sys
import os
import io
from pathlib import Path
from datetime import datetime

# è®¾ç½®UTF-8ç¼–ç è¾“å‡ºï¼ˆWindowså…¼å®¹ï¼‰
if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from app.core.database import SessionLocal
from app.models.sys_user import SysUser
from app.models.import_batch import ImportBatch
from app.services.ingest_template_detector import detect_template
from app.services.ingestors import import_lh_ftr, import_lh_opt
from app.services.ingestors.unified_ingestor import unified_import


def get_or_create_test_user(db):
    """è·å–æˆ–åˆ›å»ºæµ‹è¯•ç”¨æˆ·"""
    # ä¼˜å…ˆä½¿ç”¨adminç”¨æˆ·
    user = db.query(SysUser).filter(SysUser.username == "admin").first()
    if not user:
        # å¦‚æœæ²¡æœ‰adminï¼Œåˆ›å»ºtest_admin
        from app.core.security import get_password_hash
        user = SysUser(
            username="test_admin",
            password_hash=get_password_hash("test123456"),
            display_name="æµ‹è¯•ç®¡ç†å‘˜",
            is_active=True
        )
        db.add(user)
        db.commit()
        db.refresh(user)
        print(f"  âœ“ åˆ›å»ºæµ‹è¯•ç”¨æˆ·: {user.username} (ID: {user.id})")
    else:
        print(f"  âœ“ ä½¿ç”¨ç°æœ‰ç”¨æˆ·: {user.username} (ID: {user.id})")
    return user


def create_batch_for_legacy_import(db, filename, source_code, uploader_id):
    """ä¸ºæ—§å¯¼å…¥å™¨åˆ›å»ºæ‰¹æ¬¡"""
    batch = ImportBatch(
        filename=filename,
        file_hash="",  # æ—§å¯¼å…¥å™¨å¯èƒ½ä¸éœ€è¦hash
        uploader_id=uploader_id,
        status="processing",
        source_code=source_code,
        total_rows=0,
        success_rows=0,
        failed_rows=0
    )
    db.add(batch)
    db.commit()
    db.refresh(batch)
    return batch.id


def import_file(db, file_path: Path, uploader_id: int):
    """å¯¼å…¥å•ä¸ªæ–‡ä»¶"""
    filename = file_path.name
    print(f"\n{'='*60}")
    print(f"å¤„ç†æ–‡ä»¶: {filename}")
    print(f"{'='*60}")
    
    if not file_path.exists():
        print(f"  âœ— æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        return {
            "success": False,
            "error": f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}"
        }
    
    # è¯»å–æ–‡ä»¶å†…å®¹
    try:
        with open(file_path, 'rb') as f:
            file_content = f.read()
        print(f"  âœ“ æ–‡ä»¶å¤§å°: {len(file_content) / 1024:.2f} KB")
    except Exception as e:
        print(f"  âœ— è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
        return {
            "success": False,
            "error": f"è¯»å–æ–‡ä»¶å¤±è´¥: {e}"
        }
    
    # æ£€æµ‹æ¨¡æ¿ç±»å‹
    try:
        template_type = detect_template(file_content, filename)
        print(f"  âœ“ æ£€æµ‹åˆ°æ¨¡æ¿ç±»å‹: {template_type}")
    except Exception as e:
        print(f"  âœ— æ¨¡æ¿æ£€æµ‹å¤±è´¥: {e}")
        return {
            "success": False,
            "error": f"æ¨¡æ¿æ£€æµ‹å¤±è´¥: {e}"
        }
    
    # æ ¹æ®æ¨¡æ¿ç±»å‹é€‰æ‹©å¯¼å…¥æ–¹å¼
    start_time = datetime.now()
    result = None
    
    try:
        if template_type == "LH_FTR":
            print("  â†’ ä½¿ç”¨æœŸè´§å¯¼å…¥å™¨...")
            batch_id = create_batch_for_legacy_import(db, filename, "DCE", uploader_id)
            result = import_lh_ftr(db, file_content, batch_id)
            
        elif template_type == "LH_OPT":
            print("  â†’ ä½¿ç”¨æœŸæƒå¯¼å…¥å™¨...")
            batch_id = create_batch_for_legacy_import(db, filename, "DCE", uploader_id)
            result = import_lh_opt(db, file_content, batch_id)
            
        elif template_type == "YONGYI_DAILY":
            print("  â†’ ä½¿ç”¨ç»Ÿä¸€å¯¼å…¥å·¥ä½œæµ (YONGYI_DAILY)...")
            result = unified_import(
                db=db,
                file_content=file_content,
                filename=filename,
                uploader_id=uploader_id,
                dataset_type="YONGYI_DAILY",
                source_code="YONGYI"
            )
            
        elif template_type == "YONGYI_WEEKLY":
            print("  â†’ ä½¿ç”¨ç»Ÿä¸€å¯¼å…¥å·¥ä½œæµ (YONGYI_WEEKLY)...")
            result = unified_import(
                db=db,
                file_content=file_content,
                filename=filename,
                uploader_id=uploader_id,
                dataset_type="YONGYI_WEEKLY",
                source_code="YONGYI"
            )
            
        elif template_type == "GANGLIAN_DAILY":
            print("  â†’ ä½¿ç”¨é’¢è”å¯¼å…¥å™¨...")
            from app.services.ingestors import import_ganglian_daily
            batch_id = create_batch_for_legacy_import(db, filename, "MYSTEEL", uploader_id)
            result = import_ganglian_daily(db, file_content, batch_id)
            
        else:
            print(f"  âœ— ä¸æ”¯æŒçš„æ¨¡æ¿ç±»å‹: {template_type}")
            return {
                "success": False,
                "error": f"ä¸æ”¯æŒçš„æ¨¡æ¿ç±»å‹: {template_type}"
            }
        
        # æ˜¾ç¤ºç»“æœ
        duration = (datetime.now() - start_time).total_seconds()
        if result.get("success"):
            inserted = result.get("inserted", 0)
            updated = result.get("updated", 0)
            errors = result.get("errors", 0)
            if isinstance(errors, list):
                errors = len(errors)
            
            print(f"\n  âœ“ å¯¼å…¥æˆåŠŸï¼")
            print(f"     - æ–°å¢: {inserted} æ¡")
            print(f"     - æ›´æ–°: {updated} æ¡")
            print(f"     - é”™è¯¯: {errors} æ¡")
            print(f"     - è€—æ—¶: {duration:.2f} ç§’")
            
            if result.get("total_sheets"):
                print(f"     - Sheetæ•°: {result.get('total_sheets')}")
            if result.get("parsed_sheets"):
                print(f"     - å·²è§£æ: {result.get('parsed_sheets')}")
            
            return {
                "success": True,
                "inserted": inserted,
                "updated": updated,
                "errors": errors,
                "duration": duration,
                "batch_id": result.get("batch_id")
            }
        else:
            error_msg = result.get("error") or str(result.get("errors", []))
            print(f"\n  âœ— å¯¼å…¥å¤±è´¥: {error_msg}")
            return {
                "success": False,
                "error": error_msg,
                "duration": duration
            }
            
    except Exception as e:
        db.rollback()
        error_msg = str(e)
        print(f"\n  âœ— å¯¼å…¥å¼‚å¸¸: {error_msg}")
        import traceback
        traceback.print_exc()
        return {
            "success": False,
            "error": error_msg,
            "duration": (datetime.now() - start_time).total_seconds()
        }


def verify_import_results(db):
    """éªŒè¯å¯¼å…¥ç»“æœ"""
    print(f"\n{'='*60}")
    print("éªŒè¯å¯¼å…¥ç»“æœ")
    print(f"{'='*60}")
    
    # æ£€æŸ¥æ‰¹æ¬¡
    batches = db.query(ImportBatch).order_by(ImportBatch.id.desc()).limit(10).all()
    print(f"\næœ€è¿‘ {len(batches)} ä¸ªæ‰¹æ¬¡:")
    for batch in batches:
        status_icon = "âœ“" if batch.status == "success" else "âš " if batch.status == "partial" else "âœ—"
        print(f"  {status_icon} [{batch.id}] {batch.filename}")
        print(f"     çŠ¶æ€: {batch.status}, æˆåŠŸ: {batch.success_rows}, å¤±è´¥: {batch.failed_rows}")
    
    # æ£€æŸ¥äº‹å®è¡¨æ•°æ®é‡
    try:
        from app.models.fact_observation import FactObservation
        obs_count = db.query(FactObservation).count()
        print(f"\n  fact_observation è®°å½•æ•°: {obs_count}")
    except:
        pass
    
    try:
        from app.models.fact_futures_daily import FactFuturesDaily
        ftr_count = db.query(FactFuturesDaily).count()
        print(f"  fact_futures_daily è®°å½•æ•°: {ftr_count}")
    except:
        pass
    
    try:
        from app.models.fact_options_daily import FactOptionsDaily
        opt_count = db.query(FactOptionsDaily).count()
        print(f"  fact_options_daily è®°å½•æ•°: {opt_count}")
    except:
        pass
    
    try:
        from app.models.fact_indicator_ts import FactIndicatorTs
        ind_count = db.query(FactIndicatorTs).count()
        print(f"  fact_indicator_ts è®°å½•æ•°: {ind_count}")
    except:
        pass


def main():
    """ä¸»å‡½æ•°"""
    print("="*60)
    print("äº”ç±»æ•°æ®å…¨é‡å…¥åº“è‡ªæµ‹è„šæœ¬")
    print("="*60)
    
    # ç¡®å®šæ–‡ä»¶è·¯å¾„
    script_dir = Path(__file__).parent
    project_root = script_dir.parent.parent  # backend -> project root
    docs_dir = project_root / "docs"
    
    # å®šä¹‰è¦å¯¼å…¥çš„æ–‡ä»¶
    files_to_import = [
        {
            "path": docs_dir / "1ã€ä»·æ ¼ï¼šé’¢è”è‡ªåŠ¨æ›´æ–°æ¨¡æ¿.xlsx",
            "expected_type": "GANGLIAN_DAILY",
            "name": "é’¢è”ä»·æ ¼æ¨¡æ¿"
        },
        {
            "path": docs_dir / "2026å¹´2æœˆ2æ—¥æ¶Œç›Šå’¨è¯¢æ—¥åº¦æ•°æ®.xlsx",
            "expected_type": "YONGYI_DAILY",
            "name": "æ¶Œç›Šæ—¥åº¦æ•°æ®"
        },
        {
            "path": docs_dir / "lh_ftr.xlsx",
            "expected_type": "LH_FTR",
            "name": "DCE ç”ŸçŒªæœŸè´§"
        },
        {
            "path": docs_dir / "lh_opt.xlsx",
            "expected_type": "LH_OPT",
            "name": "DCE ç”ŸçŒªæœŸæƒ"
        },
        {
            "path": docs_dir / "2026.1.16-2026.1.22æ¶Œç›Šå’¨è¯¢ å‘¨åº¦æ•°æ®.xlsx",
            "expected_type": "YONGYI_WEEKLY",
            "name": "æ¶Œç›Šå‘¨åº¦æ•°æ®"
        }
    ]
    
    db = SessionLocal()
    results = []
    
    try:
        # 1. è·å–æˆ–åˆ›å»ºæµ‹è¯•ç”¨æˆ·
        print("\n1. å‡†å¤‡æµ‹è¯•ç”¨æˆ·...")
        user = get_or_create_test_user(db)
        
        # 2. æ£€æŸ¥é…ç½®æ–‡ä»¶æ˜¯å¦å·²åŠ è½½
        print("\n2. æ£€æŸ¥é…ç½®...")
        from app.models.ingest_profile import IngestProfile
        profiles = db.query(IngestProfile).filter(IngestProfile.is_active == "Y").all()
        if profiles:
            print(f"  âœ“ æ‰¾åˆ° {len(profiles)} ä¸ªæ´»è·ƒé…ç½®:")
            for profile in profiles:
                print(f"     - {profile.profile_code} ({profile.dataset_type})")
        else:
            print("  âš  è­¦å‘Šï¼šæœªæ‰¾åˆ°æ´»è·ƒé…ç½®ï¼Œè¯·å…ˆè¿è¡Œ load_ingest_profiles.py")
        
        # 3. é€ä¸ªå¯¼å…¥æ–‡ä»¶
        print("\n3. å¼€å§‹å¯¼å…¥æ•°æ®...")
        for i, file_info in enumerate(files_to_import, 1):
            print(f"\n[{i}/{len(files_to_import)}] {file_info['name']}")
            result = import_file(db, file_info["path"], user.id)
            result["file_name"] = file_info["name"]
            result["file_path"] = str(file_info["path"])
            results.append(result)
            
            # å¦‚æœå¤±è´¥ï¼Œè‡ªåŠ¨ç»§ç»­ï¼ˆéäº¤äº’å¼ç¯å¢ƒï¼‰
            if not result.get("success"):
                print(f"\n  [WARN] {file_info['name']} import failed, continuing...")
        
        # 4. éªŒè¯å¯¼å…¥ç»“æœ
        verify_import_results(db)
        
        # 5. æ±‡æ€»ç»“æœ
        print(f"\n{'='*60}")
        print("å¯¼å…¥æ±‡æ€»")
        print(f"{'='*60}")
        
        success_count = sum(1 for r in results if r.get("success"))
        total_inserted = sum(r.get("inserted", 0) for r in results)
        total_updated = sum(r.get("updated", 0) for r in results)
        total_errors = sum(r.get("errors", 0) if isinstance(r.get("errors"), int) else 0 for r in results)
        total_duration = sum(r.get("duration", 0) for r in results)
        
        print(f"\næˆåŠŸå¯¼å…¥: {success_count}/{len(results)} ä¸ªæ–‡ä»¶")
        print(f"æ€»æ–°å¢: {total_inserted} æ¡")
        print(f"æ€»æ›´æ–°: {total_updated} æ¡")
        print(f"æ€»é”™è¯¯: {total_errors} æ¡")
        print(f"æ€»è€—æ—¶: {total_duration:.2f} ç§’")
        
        print("\nè¯¦ç»†ç»“æœ:")
        for result in results:
            status = "âœ“" if result.get("success") else "âœ—"
            print(f"  {status} {result.get('file_name')}")
            if result.get("success"):
                print(f"     æ–°å¢: {result.get('inserted', 0)}, æ›´æ–°: {result.get('updated', 0)}, é”™è¯¯: {result.get('errors', 0)}")
            else:
                print(f"     é”™è¯¯: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
        
        if success_count == len(results):
            print("\nğŸ‰ æ‰€æœ‰æ–‡ä»¶å¯¼å…¥æˆåŠŸï¼")
        else:
            print(f"\nâš  æœ‰ {len(results) - success_count} ä¸ªæ–‡ä»¶å¯¼å…¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")
        
    except Exception as e:
        print(f"\nâœ— æ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        db.rollback()
    finally:
        db.close()


if __name__ == "__main__":
    main()
