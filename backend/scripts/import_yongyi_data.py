"""
å¯¼å…¥æ¶Œç›Šå’¨è¯¢æ•°æ®æ–‡ä»¶
æ”¯æŒæ—¥åº¦å’Œå‘¨åº¦æ•°æ®å¯¼å…¥
"""
# -*- coding: utf-8 -*-
import sys
import io
from pathlib import Path
from sqlalchemy.orm import Session
from datetime import datetime
import hashlib

script_dir = Path(__file__).parent.parent
sys.path.insert(0, str(script_dir))

sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

from app.core.database import SessionLocal
from app.models.sys_user import SysUser
from app.services.ingestors.unified_ingestor import unified_import

def get_or_create_test_user(db: Session) -> SysUser:
    """è·å–æˆ–åˆ›å»ºæµ‹è¯•ç”¨æˆ·"""
    user = db.query(SysUser).filter(SysUser.username == "admin").first()
    if not user:
        user = SysUser(
            username="admin",
            email="admin@example.com",
            full_name="Admin User",
            is_active=True,
            is_superuser=True
        )
        db.add(user)
        db.commit()
        db.refresh(user)
    return user

def import_yongyi_file(file_path: Path, dataset_type: str, file_name: str):
    """å¯¼å…¥å•ä¸ªæ¶Œç›Šæ–‡ä»¶"""
    if not file_path.exists():
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        return False
    
    print(f"\n{'='*80}")
    print(f"å¯¼å…¥æ–‡ä»¶: {file_name}")
    print(f"æ–‡ä»¶è·¯å¾„: {file_path}")
    print(f"æ•°æ®ç±»å‹: {dataset_type}")
    print(f"{'='*80}")
    
    db = SessionLocal()
    try:
        # è·å–æˆ–åˆ›å»ºç”¨æˆ·
        user = get_or_create_test_user(db)
        
        # è¯»å–æ–‡ä»¶å†…å®¹
        with open(file_path, 'rb') as f:
            file_content = f.read()
        
        print(f"\nğŸ“ æ–‡ä»¶ä¿¡æ¯:")
        print(f"  æ–‡ä»¶å: {file_path.name}")
        print(f"  æ–‡ä»¶å¤§å°: {len(file_content) / 1024 / 1024:.2f} MB")
        
        # ä½¿ç”¨ç»Ÿä¸€å¯¼å…¥å·¥ä½œæµ
        print(f"\nğŸš€ å¼€å§‹å¯¼å…¥...")
        try:
            result = unified_import(
                db=db,
                file_content=file_content,
                filename=file_path.name,
                uploader_id=user.id,
                dataset_type=dataset_type,
                source_code=None  # è‡ªåŠ¨æ¨æ–­
            )
        except ValueError as e:
            # æ•è·è§£æå™¨ç±»å‹é”™è¯¯ï¼Œä½†ç»§ç»­å¤„ç†å…¶ä»–sheet
            if "æœªçŸ¥çš„è§£æå™¨ç±»å‹" in str(e) or "æœªçŸ¥çš„è§£æå™¨ç±»å‹" in repr(e):
                print(f"\nâš ï¸  é‡åˆ°ä¸æ”¯æŒçš„è§£æå™¨ç±»å‹ï¼Œä½†éƒ¨åˆ†æ•°æ®å¯èƒ½å·²å¯¼å…¥")
                print(f"  é”™è¯¯: {e}")
                # å°è¯•è·å–éƒ¨åˆ†ç»“æœ
                result = {
                    "batch_id": None,
                    "total_sheets": 0,
                    "parsed_sheets": 0,
                    "inserted_count": 0,
                    "updated_count": 0,
                    "error_count": 1,
                    "errors": [str(e)]
                }
            else:
                raise
        
        print(f"\nâœ… å¯¼å…¥å®Œæˆ!")
        print(f"  æ‰¹æ¬¡ID: {result.get('batch_id')}")
        print(f"  æ€»sheetæ•°: {result.get('total_sheets', 0)}")
        print(f"  å·²è§£æsheetæ•°: {result.get('parsed_sheets', 0)}")
        print(f"  æ–°å¢è®°å½•æ•°: {result.get('inserted_count', 0)}")
        print(f"  æ›´æ–°è®°å½•æ•°: {result.get('updated_count', 0)}")
        print(f"  é”™è¯¯æ•°: {result.get('error_count', 0)}")
        
        if result.get('errors'):
            print(f"\nâš ï¸  é”™è¯¯ä¿¡æ¯:")
            for error in result['errors'][:10]:  # åªæ˜¾ç¤ºå‰10ä¸ªé”™è¯¯
                print(f"  - {error}")
            if len(result['errors']) > 10:
                print(f"  ... è¿˜æœ‰ {len(result['errors']) - 10} ä¸ªé”™è¯¯")
        
        db.commit()
        return True
        
    except Exception as e:
        db.rollback()
        print(f"\nâŒ å¯¼å…¥å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False
    finally:
        db.close()

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 80)
    print("æ¶Œç›Šå’¨è¯¢æ•°æ®å¯¼å…¥è„šæœ¬")
    print("=" * 80)
    
    # ç¡®å®šæ–‡ä»¶è·¯å¾„
    project_root = script_dir.parent
    docs_dir = project_root / "docs" / "ç”ŸçŒª" / "æ¶Œç›Šç”ŸçŒªé¡¹ç›®æ•°æ®åº“_2" / "æ¶Œç›Šç”ŸçŒªé¡¹ç›®æ•°æ®åº“"
    
    # å®šä¹‰è¦å¯¼å…¥çš„æ–‡ä»¶
    files_to_import = [
        {
            "path": docs_dir / "æ¶Œç›Šå’¨è¯¢ å‘¨åº¦æ•°æ®.xlsx",
            "dataset_type": "YONGYI_WEEKLY",
            "name": "æ¶Œç›Šå’¨è¯¢ å‘¨åº¦æ•°æ®"
        },
        {
            "path": docs_dir / "æ¶Œç›Šå’¨è¯¢æ—¥åº¦æ•°æ®.xlsx",
            "dataset_type": "YONGYI_DAILY",
            "name": "æ¶Œç›Šå’¨è¯¢æ—¥åº¦æ•°æ®"
        }
    ]
    
    results = []
    
    for file_info in files_to_import:
        success = import_yongyi_file(
            file_info["path"],
            file_info["dataset_type"],
            file_info["name"]
        )
        results.append({
            "name": file_info["name"],
            "success": success
        })
    
    # æ±‡æ€»ç»“æœ
    print(f"\n{'='*80}")
    print("å¯¼å…¥æ±‡æ€»")
    print(f"{'='*80}")
    
    success_count = sum(1 for r in results if r["success"])
    total_count = len(results)
    
    for result in results:
        status = "âœ… æˆåŠŸ" if result["success"] else "âŒ å¤±è´¥"
        print(f"  {status} - {result['name']}")
    
    print(f"\næ€»è®¡: {success_count}/{total_count} ä¸ªæ–‡ä»¶å¯¼å…¥æˆåŠŸ")
    
    if success_count == total_count:
        print("\nğŸ‰ æ‰€æœ‰æ–‡ä»¶å¯¼å…¥æˆåŠŸ!")
    else:
        print(f"\nâš ï¸  æœ‰ {total_count - success_count} ä¸ªæ–‡ä»¶å¯¼å…¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")

if __name__ == "__main__":
    main()
