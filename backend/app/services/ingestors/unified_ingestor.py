"""ç»Ÿä¸€å¯¼å…¥å·¥ä½œæµ - æ•´åˆRawå±‚ã€Dispatcherã€Parserã€Validatorã€Upsertã€Extractor"""
from typing import Dict, Any, List, Optional
from datetime import datetime
from sqlalchemy.orm import Session
from openpyxl import load_workbook
from io import BytesIO
import hashlib

from app.models.import_batch import ImportBatch
from app.services.ingestors.raw_writer import (
    save_raw_file, save_all_sheets_from_workbook, update_sheet_parse_status
)
from app.services.ingestors.dispatcher import create_dispatcher, Dispatcher
from app.services.ingestors.error_collector import ErrorCollector
from app.services.ingestors.parsers import get_parser, PARSER_REGISTRY
from app.services.ingestors.profile_loader import get_profile_by_dataset_type
from app.services.ingestors.observation_upserter import upsert_observations
from app.services.ingestors.validator import ObservationValidator


def unified_import(
    db: Session,
    file_content: bytes,
    filename: str,
    uploader_id: int,
    dataset_type: str,
    source_code: Optional[str] = None
) -> Dict[str, Any]:
    """
    ç»Ÿä¸€å¯¼å…¥å·¥ä½œæµ
    
    å·¥ä½œæµï¼š
    1. åˆ›å»ºimport_batch
    2. ä¿å­˜raw_fileï¼ˆæ–‡ä»¶åã€hashã€æ—¥æœŸèŒƒå›´ï¼‰
    3. è¯»å–workbookï¼ŒéåŽ†æ¯ä¸ªsheetï¼š
       - ä¿å­˜raw_sheet + raw_table
       - Dispatcheråˆ†æ´¾parser
       - è°ƒç”¨å¯¹åº”parserè§£æž
       - éªŒè¯æ•°æ®ï¼ˆvalidateï¼‰
       - å¹‚ç­‰upsertåˆ°fact_observation
       - è®°å½•é”™è¯¯åˆ°ingest_error
    4. è§¦å‘æŒ‡æ ‡æŠ½å–ï¼ˆextract_indicatorsï¼‰
    5. æ›´æ–°batchçŠ¶æ€
    
    Args:
        db: æ•°æ®åº“ä¼šè¯
        file_content: æ–‡ä»¶å†…å®¹ï¼ˆbytesï¼‰
        filename: æ–‡ä»¶å
        uploader_id: ä¸Šä¼ è€…ID
        dataset_type: æ•°æ®é›†ç±»åž‹ï¼ˆYONGYI_DAILY/YONGYI_WEEKLY/GANGLIAN_DAILYç­‰ï¼‰
        source_code: æ•°æ®æºä»£ç ï¼ˆå¯é€‰ï¼Œä»Ždataset_typeæŽ¨æ–­ï¼‰
    
    Returns:
        å¯¼å…¥ç»“æžœå­—å…¸
    """
    start_time = datetime.now()
    errors = []
    inserted_count = 0
    updated_count = 0
    error_count = 0
    total_sheets = 0
    parsed_sheets = 0
    batch = None
    
    try:
        # 1. åˆ›å»ºimport_batch
        file_hash = hashlib.sha256(file_content).hexdigest()
        batch = ImportBatch(
            filename=filename,
            file_hash=file_hash,
            uploader_id=uploader_id,
            status="processing",
            source_code=source_code or dataset_type,
            total_rows=0,
            success_rows=0,
            failed_rows=0
        )
        db.add(batch)
        db.flush()
        batch_id = batch.id
        
        # 2. ä¿å­˜raw_file
        raw_file = save_raw_file(
            db=db,
            batch_id=batch_id,
            filename=filename,
            file_content=file_content
        )
        
        # 3. åŠ è½½profileå’Œåˆ›å»ºdispatcher
        profile = get_profile_by_dataset_type(db, dataset_type)
        if not profile:
            # å°è¯•è‡ªåŠ¨åŠ è½½é…ç½®æ–‡ä»¶
            print(f"  âš ï¸  Profileä¸å­˜åœ¨ï¼Œå°è¯•è‡ªåŠ¨åŠ è½½...", flush=True)
            from app.services.ingestors.profile_loader import load_profile_from_json
            from pathlib import Path
            import os
            
            # æŸ¥æ‰¾é…ç½®æ–‡ä»¶
            script_dir = Path(__file__).parent.parent.parent
            project_root = script_dir.parent if script_dir.name == 'app' else script_dir
            docs_dir = project_root / 'docs'
            
            profile_file_map = {
                'YONGYI_WEEKLY': 'ingest_profile_yongyi_weekly_v1.json',
                'YONGYI_DAILY': 'ingest_profile_yongyi_daily_v1.json',
                'GANGLIAN_DAILY': 'ingest_profile_ganglian_daily_v1.json',
                'ENTERPRISE_DAILY': 'ingest_profile_enterprise_daily_v1.json'
            }
            
            profile_file = profile_file_map.get(dataset_type)
            if profile_file:
                json_path = docs_dir / profile_file
                if json_path.exists():
                    try:
                        profile = load_profile_from_json(db, str(json_path))
                        print(f"  âœ“ æˆåŠŸåŠ è½½Profile: {profile.profile_code} ({len(profile.sheets)} sheets)", flush=True)
                    except Exception as e:
                        print(f"  âŒ åŠ è½½Profileå¤±è´¥: {e}", flush=True)
                        raise ValueError(f"æœªæ‰¾åˆ°profileä¸”è‡ªåŠ¨åŠ è½½å¤±è´¥: dataset_type={dataset_type}, error={e}")
                else:
                    raise ValueError(f"æœªæ‰¾åˆ°profileä¸”é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {json_path}")
            else:
                raise ValueError(f"æœªæ‰¾åˆ°profile: dataset_type={dataset_type}")
        
        if not profile.sheets or len(profile.sheets) == 0:
            raise ValueError(f"Profileå­˜åœ¨ä½†sheetsé…ç½®ä¸ºç©º: profile_code={profile.profile_code}")
        
        print(f"  âœ“ Profileå·²åŠ è½½: {profile.profile_code} ({len(profile.sheets)} sheets)", flush=True)
        
        dispatcher = Dispatcher(db, profile)
        error_collector = ErrorCollector(db, batch_id)
        
        # 4. è¯»å–workbookå¹¶ä¿å­˜æ‰€æœ‰sheetåˆ°rawå±‚
        workbook = load_workbook(BytesIO(file_content), data_only=True)
        # ä½¿ç”¨sparseæ ¼å¼å’Œé™åˆ¶è¡Œæ•°æ¥ä¼˜åŒ–å­˜å‚¨
        # å¯¹äºŽè¶…å¤§sheetï¼Œsave_raw_tableä¼šè‡ªåŠ¨è·³è¿‡å­˜å‚¨ï¼ˆåªä¿ç•™å…ƒä¿¡æ¯ï¼‰
        raw_sheets = save_all_sheets_from_workbook(
            db=db,
            raw_file_id=raw_file.id,
            workbook_or_path=workbook,
            sparse=True,  # ä½¿ç”¨ç¨€ç–æ ¼å¼
            max_rows=None  # Noneè¡¨ç¤ºç”±save_raw_tableæ ¹æ®sheetå¤§å°è‡ªåŠ¨å†³å®š
        )
        total_sheets = len(raw_sheets)
        
        # 5. éåŽ†æ¯ä¸ªsheetè¿›è¡Œå¤„ç†
        for sheet_idx, raw_sheet in enumerate(raw_sheets, 1):
            sheet_name = raw_sheet.sheet_name
            
            # è®°å½•sheetå¤„ç†å¼€å§‹ï¼ˆå¼ºåˆ¶åˆ·æ–°è¾“å‡ºï¼‰
            print(f"\n  ðŸ“„ å¤„ç†Sheet [{sheet_idx}/{total_sheets}]: {sheet_name}", flush=True)
            print(f"     â””â”€ å¼€å§‹æ—¶é—´: {datetime.now().strftime('%H:%M:%S')}", flush=True)
            
            # å¯¼å…¥å‰ï¼šèŽ·å–ç›®æ ‡è¡¨çš„è®°å½•æ•°ï¼ˆå¦‚æžœæœ‰table_configï¼‰
            table_name = None
            table_config = None
            count_before = None
            if raw_sheet.parse_status == "parsed":
                # å°è¯•èŽ·å–sheet_configä»¥ç¡®å®šç›®æ ‡è¡¨
                try:
                    sheet_config = dispatcher.get_sheet_config(sheet_name)
                    if sheet_config:
                        table_config = sheet_config.get("table_config")
                        if table_config:
                            table_name = table_config.get("table_name")
                            if table_name:
                                from sqlalchemy import text, inspect
                                inspector = inspect(db.bind)
                                if table_name in inspector.get_table_names():
                                    result = db.execute(text(f"SELECT COUNT(*) as cnt FROM `{table_name}`"))
                                    row = result.fetchone()
                                    count_before = row[0] if row else 0
                                    print(f"     â””â”€ å¯¼å…¥å‰è®°å½•æ•°: {count_before} (è¡¨: {table_name})")
                except Exception:
                    pass
            sheet_name = raw_sheet.sheet_name
            worksheet = workbook[sheet_name]
            
            try:
                # 5.1 Dispatcheråˆ†æ´¾parserï¼ˆå¦‚æžœä¸Šé¢å·²ç»dispatchè¿‡ï¼Œè¿™é‡Œå¯ä»¥é‡ç”¨ç»“æžœï¼‰
                # ä¸ºäº†ä»£ç æ¸…æ™°ï¼Œè¿™é‡Œé‡æ–°dispatchï¼ˆå®žé™…å¯ä»¥ä¼˜åŒ–ï¼‰
                dispatch_result = dispatcher.dispatch_sheet(
                    sheet_name=sheet_name,
                    worksheet=worksheet
                )
                
                action = dispatch_result.get("action")
                parser_type = dispatch_result.get("parser")
                sheet_config = dispatch_result.get("sheet_config")
                
                # å¦‚æžœä¸Šé¢å·²ç»èŽ·å–äº†table_nameå’Œcount_beforeï¼Œè¿™é‡Œé‡ç”¨
                if sheet_config and not table_name:
                    table_config = sheet_config.get("table_config")
                    if table_config:
                        from app.services.sheet_table_mapper import get_table_name_for_sheet
                        table_name = table_config.get("table_name") or get_table_name_for_sheet(
                            sheet_name=sheet_name,
                            source_code=profile.source_code,
                            dataset_type=profile.dataset_type
                        )
                
                # 5.2 æ ¹æ®actionå¤„ç†
                if action == "SKIP_META":
                    print(f"     â””â”€ â­ï¸  è·³è¿‡ï¼ˆå…ƒæ•°æ®sheetï¼‰", flush=True)
                    update_sheet_parse_status(
                        db=db,
                        raw_sheet_id=raw_sheet.id,
                        parse_status="skipped",
                        parser_type=None
                    )
                    continue
                
                elif action == "RAW_TABLE_STORE_ONLY":
                    print(f"     â””â”€ ðŸ“¦ ä»…å­˜å‚¨åˆ°raw_tableï¼ˆä¸è§£æžï¼‰", flush=True)
                    update_sheet_parse_status(
                        db=db,
                        raw_sheet_id=raw_sheet.id,
                        parse_status="raw_only",
                        parser_type=None
                    )
                    continue
                
                elif action == "PARSE" and parser_type and sheet_config:
                    # 5.3 è°ƒç”¨parserè§£æž
                    table_config = sheet_config.get("table_config")
                    
                    print(f"     â””â”€ ä½¿ç”¨è§£æžå™¨: {parser_type}", flush=True)
                    if table_config:
                        print(f"     â””â”€ ç›®æ ‡è¡¨: {table_config.get('table_name', 'æœªçŸ¥')}", flush=True)
                    
                    try:
                        parser = get_parser(parser_type)
                    except ValueError as e:
                        error_msg = str(e)
                        if "æœªçŸ¥çš„è§£æžå™¨ç±»åž‹" in error_msg:
                            print(f"     â””â”€ âŒ Sheetå¤„ç†å¤±è´¥: {error_msg}", flush=True)
                            error_collector.add_error(
                                sheet_name=sheet_name,
                                row_no=None,
                                column=None,
                                error_type="PARSER_NOT_FOUND",
                                error_message=f"ä¸æ”¯æŒçš„è§£æžå™¨ç±»åž‹: {parser_type}",
                                raw_value=None,
                                context=f"sheet_name={sheet_name}, parser_type={parser_type}"
                            )
                            # æ›´æ–°sheetçŠ¶æ€
                            update_sheet_parse_status(
                                db=db,
                                raw_sheet_id=raw_sheet.id,
                                parse_status="failed",
                                parser_type=parser_type,
                                error_count=1
                            )
                            continue
                        else:
                            raise
                    
                    print(f"     â””â”€ å¼€å§‹è§£æžæ•°æ®...", flush=True)
                    
                    # è°ƒè¯•ï¼šæ£€æŸ¥sheet_configæ˜¯å¦åŒ…å«metric_template
                    if sheet_config:
                        metric_template = sheet_config.get("metric_template")
                        if not metric_template:
                            print(f"     â””â”€ âš ï¸  sheet_configä¸­æ²¡æœ‰metric_templateï¼", flush=True)
                            print(f"         sheet_config.keys()={list(sheet_config.keys())[:15]}", flush=True)
                        else:
                            metric_key = metric_template.get("metric_key", "")
                            print(f"     â””â”€ âœ“ metric_templateå­˜åœ¨: metric_key={metric_key}", flush=True)
                    
                    observations = parser.parse(
                        sheet_data=worksheet,
                        sheet_config=sheet_config,
                        profile_defaults=profile.defaults_json or {},
                        source_code=profile.source_code,
                        batch_id=batch.id
                    )
                    
                    print(f"     â””â”€ è§£æžå¾—åˆ°è§‚æµ‹å€¼: {len(observations)} æ¡", flush=True)
                    
                    # 5.4 éªŒè¯æ•°æ®
                    validator = ObservationValidator(error_collector)
                    # å¯¹äºŽæ–°æž¶æž„ï¼ˆæœ‰table_configï¼‰ï¼Œè·³è¿‡metric_keyå’Œdedup_keyæ£€æŸ¥
                    skip_metric_check = bool(table_config)
                    
                    # è°ƒè¯•ï¼šæ£€æŸ¥å‰å‡ æ¡æ•°æ®çš„ç»“æž„
                    if observations and len(observations) > 0:
                        sample_obs = observations[0]
                        print(f"     â””â”€ ç¤ºä¾‹è§‚æµ‹å€¼ç»“æž„: obs_date={sample_obs.get('obs_date')}, value={sample_obs.get('value')}, period_type={sample_obs.get('period_type')}")
                    
                    valid_observations = validator.validate_batch(
                        observations, 
                        sheet_name,
                        skip_metric_key_check=skip_metric_check
                    )
                    
                    print(f"     â””â”€ éªŒè¯åŽæœ‰æ•ˆè§‚æµ‹å€¼: {len(valid_observations)} æ¡", flush=True)
                    if len(valid_observations) == 0 and len(observations) > 0:
                        # è°ƒè¯•ï¼šæŸ¥çœ‹ç¬¬ä¸€ä¸ªå¤±è´¥çš„åŽŸå› 
                        is_valid, error_msg = validator.validate_observation(
                            observations[0],
                            sheet_name,
                            row_no=1,
                            skip_metric_key_check=skip_metric_check
                        )
                        print(f"     â””â”€ âš ï¸  ç¬¬ä¸€ä¸ªè§‚æµ‹å€¼éªŒè¯å¤±è´¥: {error_msg}", flush=True)
                    
                    # 5.5 æ£€æŸ¥æ˜¯å¦æœ‰table_configï¼ˆæ–°æž¶æž„ï¼šå¯¼å…¥åˆ°ç‹¬ç«‹è¡¨ï¼‰
                    
                    if table_config and valid_observations:
                        # ä½¿ç”¨æ–°æž¶æž„ï¼šå¯¼å…¥åˆ°ç‹¬ç«‹è¡¨
                        try:
                            print(f"     â””â”€ âœ… ä½¿ç”¨æ–°æž¶æž„ï¼ˆç‹¬ç«‹è¡¨ï¼‰", flush=True)
                            from app.services.sheet_table_mapper import get_table_name_for_sheet
                            from app.services.column_mapper import ColumnMapper
                            from app.services.sheet_table_importer import SheetTableImporter
                            
                            # table_nameåœ¨sheet_configé¡¶å±‚ï¼Œä¸åœ¨table_configé‡Œé¢
                            table_name = sheet_config.get("table_name") or get_table_name_for_sheet(
                                sheet_name=sheet_name,
                                source_code=profile.source_code,
                                dataset_type=profile.dataset_type
                            )
                            
                            column_mapping = table_config.get("column_mapping", {})
                            unique_key = table_config.get("unique_key", [])
                            
                            # è½¬æ¢æ•°æ®
                            print(f"     â””â”€ å¼€å§‹è½¬æ¢æ•°æ®...", flush=True)
                            mapper = ColumnMapper()
                            records = mapper.map_observations_to_table_records(
                                observations=valid_observations,
                                column_mapping=column_mapping,
                                table_name=table_name,
                                batch_id=batch_id,
                                sheet_config=sheet_config
                            )
                            
                            # å¯¼å…¥åˆ°è¡¨
                            print(f"     â””â”€ è½¬æ¢åŽè®°å½•æ•°: {len(records)} æ¡", flush=True)
                            print(f"     â””â”€ å¼€å§‹å¯¼å…¥åˆ°è¡¨ {table_name}...", flush=True)
                            
                            importer = SheetTableImporter(db)
                            import_result = importer.import_to_table(
                                table_name=table_name,
                                records=records,
                                unique_key=unique_key
                            )
                            
                            # ========== Sheetå¯¼å…¥åŽæ—¥å¿— ==========
                            count_after = -1
                            try:
                                from sqlalchemy import inspect, text
                                inspector = inspect(db.bind)
                                if table_name in inspector.get_table_names():
                                    result_count = db.execute(text(f"SELECT COUNT(*) as cnt FROM `{table_name}`"))
                                    row = result_count.fetchone()
                                    count_after = row[0] if row else 0
                            except Exception:
                                count_after = -1
                            
                            inserted = import_result.get("inserted", 0)
                            updated = import_result.get("updated", 0)
                            errors = import_result.get("errors", 0)
                            
                            print(f"     â””â”€ âœ… Sheetå¯¼å…¥å®Œæˆ", flush=True)
                            if count_after >= 0:
                                print(f"     â””â”€ å¯¼å…¥åŽè®°å½•æ•°: {count_after}", flush=True)
                                if count_before is not None and count_before >= 0:
                                    print(f"     â””â”€ æ–°å¢žè®°å½•æ•°: {count_after - count_before}", flush=True)
                            print(f"     â””â”€ æ’å…¥: {inserted}, æ›´æ–°: {updated}, é”™è¯¯: {errors}", flush=True)
                            print(f"     â””â”€ å®Œæˆæ—¶é—´: {datetime.now().strftime('%H:%M:%S')}", flush=True)
                            
                            inserted_count += inserted
                            updated_count += updated
                            error_count += errors
                            
                            # ========== æ–°æž¶æž„ï¼šåŒæ—¶å¯¼å…¥åˆ°fact_observation ==========
                            # å¯¹äºŽæœ‰table_configçš„sheetï¼Œä¹Ÿéœ€è¦å¯¼å…¥åˆ°fact_observationä¾›å‰ç«¯æŸ¥è¯¢
                            try:
                                print(f"     â””â”€ åŒæ—¶å¯¼å…¥åˆ°fact_observation...", flush=True)
                                upsert_result = upsert_observations(
                                    db=db,
                                    observations=valid_observations,
                                    batch_id=batch_id,
                                    sheet_name=sheet_name
                                )
                                obs_inserted = upsert_result.get("inserted", 0)
                                obs_updated = upsert_result.get("updated", 0)
                                obs_errors = upsert_result.get("errors", 0)
                                print(f"     â””â”€ fact_observation: æ’å…¥: {obs_inserted}, æ›´æ–°: {obs_updated}, é”™è¯¯: {obs_errors}", flush=True)
                            except Exception as e:
                                error_msg = str(e)
                                if len(error_msg) > 200:
                                    error_msg = error_msg[:197] + "..."
                                print(f"     â””â”€ âš ï¸  å¯¼å…¥åˆ°fact_observationå¤±è´¥: {error_msg}", flush=True)
                                # ä¸å½±å“ä¸»æµç¨‹ï¼Œåªè®°å½•é”™è¯¯
                            
                        except Exception as e:
                            error_msg = str(e)
                            if len(error_msg) > 200:
                                error_msg = error_msg[:197] + "..."
                            error_collector.record_error(
                                error_type="sheet_table_import_error",
                                message=f"å¯¼å…¥åˆ°ç‹¬ç«‹è¡¨å¤±è´¥: {error_msg}",
                                sheet_name=sheet_name,
                                immediate=True
                            )
                            error_count += len(valid_observations)
                            print(f"     â””â”€ âŒ Sheetå¯¼å…¥å¤±è´¥: {error_msg}", flush=True)
                            import traceback
                            traceback.print_exc()
                    elif valid_observations:
                        # å…¼å®¹æ—§æž¶æž„ï¼šå¯¼å…¥åˆ°fact_observation
                        print(f"     â„¹ï¸  ä½¿ç”¨æ—§æž¶æž„å¯¼å…¥åˆ°fact_observation", flush=True)
                        
                        upsert_result = upsert_observations(
                            db=db,
                            observations=valid_observations,
                            batch_id=batch_id,
                            sheet_name=sheet_name
                        )
                        
                        inserted = upsert_result.get("inserted", 0)
                        updated = upsert_result.get("updated", 0)
                        errors = upsert_result.get("errors", 0)
                        
                        print(f"     âœ… Sheetå¯¼å…¥å®Œæˆ: {sheet_name}")
                        print(f"        æ’å…¥: {inserted}, æ›´æ–°: {updated}, é”™è¯¯: {errors}")
                        
                        inserted_count += inserted
                        updated_count += updated
                        error_count += errors
                    
                    observation_count = len(valid_observations)
                    
                    update_sheet_parse_status(
                        db=db,
                        raw_sheet_id=raw_sheet.id,
                        parse_status="parsed",
                        parser_type=parser_type,
                        observation_count=observation_count,
                        error_count=len(observations) - len(valid_observations)
                    )
                    
                    # è®°å½•sheetå¤„ç†å®Œæˆ
                    if table_config:
                        table_name = table_config.get("table_name")
                        if table_name:
                            try:
                                from sqlalchemy import text, inspect
                                inspector = inspect(db.bind)
                                if table_name in inspector.get_table_names():
                                    result = db.execute(text(f"SELECT COUNT(*) as cnt FROM `{table_name}`"))
                                    row = result.fetchone()
                                    count_after = row[0] if row else 0
                                    inserted = count_after - count_before if count_before is not None else 0
                                    print(f"     â””â”€ å¯¼å…¥åŽè®°å½•æ•°: {count_after} (æ–°å¢ž: {inserted})")
                                    print(f"     â””â”€ å®Œæˆæ—¶é—´: {datetime.now().strftime('%H:%M:%S')}")
                            except Exception:
                                pass
                    
                    parsed_sheets += 1
                    
                    if not valid_observations:
                        print(f"     âš ï¸  Sheetæ— æœ‰æ•ˆæ•°æ®: {sheet_name}", flush=True)
                
                else:
                    # æ— æ³•è§£æžï¼ˆä½†RAW_TABLE_STORE_ONLYä¸åº”è¯¥åˆ°è¿™é‡Œï¼‰
                    # å¦‚æžœactionæ˜¯RAW_TABLE_STORE_ONLYä½†æ²¡è¢«å¤„ç†ï¼Œè¯´æ˜Žé€»è¾‘æœ‰é—®é¢˜
                    if action == "RAW_TABLE_STORE_ONLY":
                        # è¿™ç§æƒ…å†µä¸åº”è¯¥å‘ç”Ÿï¼Œä½†ä¸ºäº†å®‰å…¨èµ·è§ï¼Œè¿˜æ˜¯æ ‡è®°ä¸ºraw_only
                        print(f"     â””â”€ âš ï¸  æœªå¤„ç†çš„RAW_TABLE_STORE_ONLYï¼Œæ ‡è®°ä¸ºraw_only")
                        update_sheet_parse_status(
                            db=db,
                            raw_sheet_id=raw_sheet.id,
                            parse_status="raw_only",
                            parser_type=None
                        )
                        continue
                    
                    # çœŸæ­£çš„æ— æ³•è§£æž
                    print(f"     â””â”€ âŒ æ— æ³•è§£æž: action={action}, parser={parser_type}")
                    error_collector.record_error(
                        error_type="parse_failed",
                        message=f"æ— æ³•åˆ†æ´¾parser: action={action}, parser={parser_type}",
                        sheet_name=sheet_name,
                        immediate=True
                    )
                    update_sheet_parse_status(
                        db=db,
                        raw_sheet_id=raw_sheet.id,
                        parse_status="failed",
                        parser_type=None
                    )
            
            except Exception as e:
                # Sheetå¤„ç†å¤±è´¥
                error_msg = str(e)
                if len(error_msg) > 200:
                    error_msg = error_msg[:197] + "..."
                print(f"     â””â”€ âŒ Sheetå¤„ç†å¤±è´¥: {error_msg}", flush=True)
                import traceback
                traceback.print_exc()
                error_collector.record_error(
                    error_type="sheet_error",
                    message=f"Sheetå¤„ç†å¤±è´¥: {error_msg}",
                    sheet_name=sheet_name,
                    immediate=True
                )
                update_sheet_parse_status(
                    db=db,
                    raw_sheet_id=raw_sheet.id,
                    parse_status="failed",
                    parser_type=None
                )
                continue
            
            # æ¯ä¸ªsheetå¤„ç†å®ŒåŽæäº¤
            db.commit()
        
        # 6. åˆ·æ–°é”™è¯¯æ”¶é›†å™¨
        error_collector.flush()
        
        # 7. è§¦å‘æŒ‡æ ‡æŠ½å–
        try:
            from app.services.indicator_extractor import extract_core_indicators
            extract_result = extract_core_indicators(db=db, batch_id=batch_id)
            # è®°å½•æŠ½å–ç»“æžœï¼ˆå¯é€‰ï¼‰
        except Exception as e:
            # æŠ½å–å¤±è´¥ä¸å½±å“å¯¼å…¥ç»“æžœ
            pass
        
        # 8. æ›´æ–°batchçŠ¶æ€
        error_count = error_collector.get_error_count()
        if batch:
            batch.status = "success" if error_count == 0 else "partial"
            batch.inserted_count = inserted_count
            batch.updated_count = updated_count
            batch.success_rows = inserted_count + updated_count
            batch.failed_rows = error_count
            batch.sheet_count = total_sheets
            
            duration_ms = int((datetime.now() - start_time).total_seconds() * 1000)
            batch.duration_ms = duration_ms
        
        db.commit()
        
        return {
            "success": True,
            "batch_id": batch_id,
            "inserted": inserted_count,
            "updated": updated_count,
            "total_sheets": total_sheets,
            "parsed_sheets": parsed_sheets,
            "errors": error_count
        }
    
    except Exception as e:
        db.rollback()
        error_msg = str(e)
        if len(error_msg) > 500:
            error_msg = error_msg[:497] + "..."
        return {
            "success": False,
            "batch_id": batch_id if 'batch_id' in locals() else None,
            "inserted": inserted_count,
            "updated": updated_count,
            "errors": [{"reason": f"å¯¼å…¥å¤±è´¥: {error_msg}"}]
        }
