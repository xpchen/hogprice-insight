# 五文件入库工作量评估

## 一、当前技术栈状态

### 1.1 已有基础设施

#### 数据模型
- ✅ `fact_observation` - 观测事实表（已支持周期字段）
- ✅ `fact_observation_tag` - 标签表（已存在）
- ✅ `dim_location` - 地理位置维度表（已存在）
- ✅ `dim_location_alias` - 地理位置别名表（已存在）
- ✅ `dim_metric` - 指标维度表（已存在）
- ✅ `dim_geo` - 地理维度表（已存在）
- ✅ `dim_source` - 数据源维度表（已存在）
- ✅ `fact_futures_daily` - 期货日度表（已存在）
- ✅ `fact_options_daily` - 期权日度表（已存在）

#### 导入器框架
- ✅ `unified_ingestor.py` - 统一导入器框架
- ✅ `observation_upserter.py` - 观测数据upsert工具
- ✅ `profile_loader.py` - 配置加载器
- ✅ `dispatcher.py` - Sheet分发器
- ✅ `validator.py` - 数据验证器
- ✅ `error_collector.py` - 错误收集器

#### 解析器（Parsers）
- ✅ `p1_narrow_date_rows.py` - 窄表日期行解析器
- ✅ `p2_wide_province_rows.py` - 宽表省份行解析器
- ✅ `p3_wide_date_grouped_subcols.py` - 宽表日期分组子列解析器
- ✅ `p4_period_start_end_wide_province.py` - 周期起止宽表省份解析器
- ✅ `p5_period_start_end_multi_col.py` - 周期起止多列解析器
- ✅ `p6_delivery_city_matrix.py` - 交割地市矩阵解析器
- ✅ `p7_ganglian_legacy_format.py` - 钢联旧格式解析器

#### 导入器实现
- ✅ `futures_ingestor.py` - 期货导入器（已实现）
- ✅ `options_ingestor.py` - 期权导入器（已实现）
- ✅ `ganglian_daily_ingestor.py` - 钢联日度导入器（已实现）
- ✅ `yongyi_daily_ingestor.py` - 涌益日度导入器（已实现）
- ✅ `yongyi_weekly_ingestor.py` - 涌益周度导入器（部分实现）

#### 配置文件
- ✅ `ingest_profile_yongyi_daily_v1.json` - 涌益日度配置（8个sheet）
- ✅ `ingest_profile_yongyi_weekly_v1.json` - 涌益周度配置（部分sheet）
- ✅ `ingest_profile_ganglian_daily_v1.json` - 钢联日度配置（7个sheet）

### 1.2 需要完善的部分

#### 数据模型
- ⚠️ 需要确认所有表是否已创建迁移脚本
- ⚠️ 需要确认索引是否完整

#### 导入器
- ⚠️ `yongyi_weekly_ingestor.py` - 目前只处理了13个主要sheet，需要扩展到65个sheet
- ⚠️ 需要确保数据写入`fact_observation`而非`fact_indicator_ts`
- ⚠️ 需要实现`fact_observation_tag`的写入逻辑

#### 解析器
- ⚠️ 需要实现更多parser类型（如`MONTHLY_AUTO`、`CROSS_SECTION_TABLE`等）
- ⚠️ 需要处理复杂表头（多级表头、合并单元格）

#### 配置
- ⚠️ 需要补充涌益周度剩余52个sheet的配置
- ⚠️ 需要完善指标映射规则

## 二、工作量分解

### Phase 1: 数据模型完善（1-2天）

#### 1.1 检查现有模型（0.5天）
- [ ] 检查所有表是否已创建迁移脚本
- [ ] 检查索引是否完整
- [ ] 检查外键约束是否正确

#### 1.2 补充缺失功能（0.5-1天）
- [ ] 确认`fact_observation_tag`写入逻辑
- [ ] 确认`dim_location`初始化数据
- [ ] 确认`dim_metric`指标字典完整性

#### 1.3 测试数据模型（0.5天）
- [ ] 创建测试数据
- [ ] 验证表结构和约束
- [ ] 验证索引性能

**小计：1-2天**

### Phase 2: 导入器实现（3-5天）

#### 2.1 完善现有导入器（1-2天）

**期货/期权导入器（0.5天）**
- ✅ 已实现，只需验证和测试

**钢联导入器（0.5天）**
- ✅ 已实现，只需验证和测试
- [ ] 确认数据写入`fact_observation`
- [ ] 确认标签写入`fact_observation_tag`

**涌益日度导入器（0.5天）**
- ✅ 已实现，只需验证和测试
- [ ] 确认8个sheet全部支持
- [ ] 确认复杂表头解析正确

**涌益周度导入器（1-2天）**
- ⚠️ 需要大幅扩展
- [ ] 当前只处理13个主要sheet，需要扩展到65个sheet
- [ ] 需要实现更多parser类型
- [ ] 需要处理复杂表头

#### 2.2 实现新Parser（1-2天）

**需要实现的Parser类型：**
- [ ] `MONTHLY_AUTO` - 月度数据自动识别（按header判断省份列）
- [ ] `CROSS_SECTION_TABLE` - 横截面数据表（快照数据）
- [ ] `PERIOD_STRING_ROWS_MULTI_METRIC` - 周期字符串行多指标
- [ ] `MONTH_ROW_YEAR_COL_MATRIX` - 月度行年度列矩阵
- [ ] `RAW_TABLE_STORE_ONLY` - 原始表存储（不入fact_observation）

**工作量估算：**
- 每个parser实现：0.5-1天
- 共5个新parser：2.5-5天
- 考虑到代码复用，实际工作量：1-2天

#### 2.3 实现标签写入逻辑（0.5天）
- [ ] 在`observation_upserter.py`中添加标签写入逻辑
- [ ] 从`tags_json`提取标签写入`fact_observation_tag`
- [ ] 实现批量写入优化

#### 2.4 测试导入器（1天）
- [ ] 单元测试
- [ ] 集成测试
- [ ] 性能测试

**小计：3-5天**

### Phase 3: 配置完善（1-2天）

#### 3.1 补充涌益周度配置（1-1.5天）

**当前状态：**
- 已有部分sheet配置（约13个主要sheet）
- 需要补充剩余52个sheet配置

**工作量估算：**
- 每个sheet配置：10-20分钟
- 52个sheet：8-17小时
- 考虑到配置模板化和批量处理，实际工作量：1-1.5天

#### 3.2 完善指标映射规则（0.5天）
- [ ] 检查`indicator_mappings.json`完整性
- [ ] 补充缺失的指标映射
- [ ] 验证映射规则正确性

**小计：1-2天**

### Phase 4: 测试与验证（1-2天）

#### 4.1 数据导入测试（0.5天）
- [ ] 测试5个文件的导入
- [ ] 验证数据完整性
- [ ] 验证数据准确性

#### 4.2 数据质量验证（0.5天）
- [ ] 检查数据重复
- [ ] 检查数据缺失
- [ ] 检查数据异常值

#### 4.3 性能优化（0.5-1天）
- [ ] 优化批量插入性能
- [ ] 优化索引使用
- [ ] 优化查询性能

**小计：1-2天**

## 三、总工作量估算

### 3.1 只入库5个文件的工作量

| Phase | 工作内容 | 工作量 | 说明 |
|-------|---------|-------|------|
| Phase 1 | 数据模型完善 | 1-2天 | 检查和完善现有模型 |
| Phase 2 | 导入器实现 | 3-5天 | 完善现有导入器，实现新parser |
| Phase 3 | 配置完善 | 1-2天 | 补充sheet配置和指标映射 |
| Phase 4 | 测试与验证 | 1-2天 | 测试、验证、优化 |
| **总计** | | **6-11天** | |

### 3.2 与完整需求对比

**如果实现完整需求（包含D、E类缺失数据）：**

| 额外工作 | 工作量 | 说明 |
|---------|-------|------|
| 数据源获取 | 2-3天 | 获取集团企业统计、统计局数据等 |
| ETL开发 | 3-5天 | 多渠道汇总、供需曲线等 |
| 爬虫/接口开发 | 2-3天 | 统计局数据爬取/接口对接 |
| 数据清洗和标准化 | 2-3天 | 多数据源数据清洗 |
| 测试和验证 | 1-2天 | 额外数据源的测试 |
| **额外总计** | **10-16天** | |

**完整需求总工作量：16-27天**

### 3.3 工作量减少比例

**只入库5个文件：6-11天**
**完整需求：16-27天**
**减少比例：约40-50%**

## 四、风险与对策

### 4.1 技术风险

#### 风险1：复杂表头解析困难
- **影响**：涌益周度数据包含多种复杂表头格式
- **概率**：中
- **影响程度**：中
- **对策**：
  - 使用配置驱动的解析器
  - 逐步完善parser，先处理简单格式
  - 复杂格式先入raw_layer，后续逐步结构化

#### 风险2：数据量大导致性能问题
- **影响**：65个sheet的数据量可能很大
- **概率**：中
- **影响程度**：中
- **对策**：
  - 分批导入（每批1000条）
  - 优化索引
  - 必要时使用分区表

#### 风险3：数据质量问题
- **影响**：Excel数据可能存在格式不一致、缺失值等问题
- **概率**：高
- **影响程度**：低
- **对策**：
  - 实现数据验证器
  - 记录错误日志
  - 允许部分失败，继续处理其他数据

### 4.2 业务风险

#### 风险1：数据缺失导致需求不完整
- **影响**：D、E类需求无法满足
- **概率**：高
- **影响程度**：中
- **对策**：
  - 先实现可覆盖的60-70%
  - 缺失部分标注"待数据源补充"
  - 后续根据实际业务需要补充

#### 风险2：指标映射不准确
- **影响**：数据查询和展示可能不准确
- **概率**：中
- **影响程度**：中
- **对策**：
  - 建立指标映射审核机制
  - 提供指标映射查询接口
  - 支持指标映射动态调整

## 五、实施建议

### 5.1 分阶段实施策略

**第一阶段：核心数据入库（6-11天）**
1. 完善数据模型（1-2天）
2. 完善5个文件的导入器（3-5天）
3. 完成核心sheet的配置（1-2天）
4. 测试验证（1-2天）

**第二阶段：派生计算（2-3天）**
1. 升贴水计算（C1）
2. 月间价差计算（C2）
3. 指标抽取到`fact_indicator_ts`（用于快速查询）

**第三阶段：前端展示（3-5天）**
1. 核心看板开发
2. 季节性图表
3. 省区对比页面

### 5.2 优先级建议

**优先级1（立即实施）：**
- Phase 1: 数据模型完善
- Phase 2: 导入器实现（核心sheet）
- Phase 3: 配置完善（核心sheet）
- Phase 4: 测试与验证

**优先级2（后续实施）：**
- 派生计算功能
- 前端展示功能
- 性能优化

**优先级3（待数据源补充）：**
- D类需求（集团企业统计）
- E3、E4需求（供需曲线、统计局数据）

## 六、结论

**如果只入库这5个文件：**

✅ **优势：**
- 工作量显著减少（6-11天 vs 完整需求16-27天）
- 核心业务数据可覆盖60-70%
- 技术风险较低（已有基础代码）
- 可以快速上线核心功能

⚠️ **限制：**
- 部分需求无法满足（D、E类统计数据）
- 需要派生计算的功能需要额外开发
- 部分指标需要确认字段

**建议：**
1. 先完成5个文件的入库，快速上线核心功能
2. 缺失的数据需求标注"待数据源补充"
3. 后续根据实际业务需要，逐步补充缺失数据源
4. 优先实现A、B类需求（核心业务数据）
5. 其次实现C类需求（派生计算）
6. 最后补充D、E类需求（待数据源补充）
